{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install required packages"
      ],
      "metadata": {
        "id": "194xXUqfBT29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "\n",
        "import pickle\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-CV7MwyCkfI",
        "outputId": "bd807ba8-a068-4c1a-c422-d75b75d835da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 21.2 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=d1b14c0338f7b3bf13367cbc7cc6c83fedb92d979b282e4c4cf342f05eed6ce9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.0 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3fL7waM3ltF",
        "outputId": "099c8c78-894f-404b-b9ce-b56d2234a2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "hImPpq10Do9V",
        "outputId": "52897ca9-92f6-4719-edac-08c0b15a4ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Point Set"
      ],
      "metadata": {
        "id": "Rv9_th9XDR8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filepath='./dhg_data.pckl'):\n",
        "    \n",
        "    file = open(filepath, 'rb')\n",
        "    data = pickle.load(file, encoding='latin1')\n",
        "    file.close()\n",
        "    return data['x_train'], data['x_test'], data['y_train'], data['y_test']"
      ],
      "metadata": {
        "id": "dIL3isAbQRwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# DHG dataset - 1393 valid sequences\n",
        "# x_train: 835 x N x 600 x 3 (records, frames, points, coordinates)\n",
        "# x_val: 279 x N x 600 x 3 (records, frames, points, coordinates)\n",
        "# x_test: 279 x N x 600 x 3 (records, frames, points, coordinates)\n",
        "# labels: classify with 14 gesture categories\n",
        "\n",
        "# x_train, x_test, y_train, y_test = load_data('dhg_data.pckl')\n",
        "x_train, x_test, y_train, y_test = load_data('/content/drive/My Drive/Colab Notebooks/674 Project/dhg_data.pckl')\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, stratify=y_train)\n",
        "y_val = y_val - 1"
      ],
      "metadata": {
        "id": "y73ywoNAQYRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x train shape: {x_train.shape}\")\n",
        "print(f\"x val shape: {x_val.shape}\")\n",
        "print(f\"x test shape: {x_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g00yvgCeQYzq",
        "outputId": "b01beb94-740e-4829-dcb7-e3eb2fb1f78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x train shape: torch.Size([835, 20, 600, 3])\n",
            "x val shape: torch.Size([279, 20, 600, 3])\n",
            "x test shape: torch.Size([279, 20, 600, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define PPN Model"
      ],
      "metadata": {
        "id": "nORgv_4HjVLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Softmax\n",
        "from torch.nn.modules.dropout import Dropout\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, LeakyReLU, GroupNorm\n",
        "\n",
        "# This helper function is from Assignment 3\n",
        "# It creates a multi-layer perceptron (consists of multiple layers of nn.Linear)\n",
        "# with specified layer construction\n",
        "def MLP(channels, enable_group_norm=True):\n",
        "    if enable_group_norm:\n",
        "        num_groups = [0]\n",
        "        for i in range(1, len(channels)):\n",
        "            if channels[i] >= 32:\n",
        "                num_groups.append(channels[i] // 32)\n",
        "            else:\n",
        "                num_groups.append(1)\n",
        "        return Seq(*[\n",
        "            Seq(Lin(channels[i - 1], channels[i]), LeakyReLU(negative_slope=0.2)\n",
        "                # , nn.Dropout(p=0.2)\n",
        "                )\n",
        "            for i in range(1, len(channels))])\n",
        "    else:\n",
        "        return Seq(*[Seq(Lin(channels[i - 1], channels[i]), LeakyReLU(negative_slope=0.2))\n",
        "                     for i in range(1, len(channels))])\n",
        "\n",
        "\n",
        "# PointNet module for extracting point descriptors\n",
        "# num_input_features: number of input raw per-point or per-vertex features\n",
        "# num_output_features: number of output per-point descriptors (23, which is 22 joints + none category)\n",
        "class PointNet(torch.nn.Module):\n",
        "    def __init__(self, num_input_features=3, num_output_features=256):\n",
        "        super(PointNet, self).__init__()\n",
        "        self.input_features = num_input_features\n",
        "        self.output_features = num_output_features\n",
        "        self.num_points = 600\n",
        "        # T-Net layer to transform\n",
        "        # self.T_net = nn.Linear(3, 3, bias=False)\n",
        "        #\n",
        "        # self.feature_transform = nn.Linear(64, 64, bias=False)\n",
        "        self.mlp = MLP([num_input_features, 32, 64, num_output_features])\n",
        "        self.featureExtractionLayer = Seq(\n",
        "            # self.T_net,\n",
        "            # self.feature_transform,\n",
        "            self.mlp\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.featureExtractionLayer(x)\n",
        "        # x -> N x F = 600 x 256\n",
        "        x = torch.max(x, -2, keepdim=True)[0]\n",
        "        return x\n",
        "  \n",
        "\n",
        "class pnGroup(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(pnGroup, self).__init__()\n",
        "        self.out_num = num_output_features\n",
        "        self.point_net = PointNet(num_input_features, num_output_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y, x = x[0], x[1:]\n",
        "        y = self.point_net(y)\n",
        "        for frame in x:\n",
        "            y = torch.cat((y, self.point_net(frame)), 0)\n",
        "\n",
        "        # y -> 20 x 256\n",
        "        return y\n",
        "\n",
        "class PPN(torch.nn.Module):\n",
        "    def __init__(self, num_input_features, num_output_features, device):\n",
        "        super(PPN, self).__init__()\n",
        "        self.device = device\n",
        "        self.png = pnGroup(num_input_features, num_output_features)\n",
        "        self.partial = True\n",
        "        self.test = False\n",
        "        self.hidden_size = num_output_features\n",
        "        self.num_layers = 3\n",
        "        self.num_points = 600\n",
        "        self.input_size = num_output_features\n",
        "        self.sequence_length = 20     # M\n",
        "        self.num_classes = 14\n",
        "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=0)\n",
        "        self.fc = Seq(\n",
        "            Lin(self.hidden_size * self.sequence_length, 128),\n",
        "            nn.Dropout(p=0.2),\n",
        "            Lin(128, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "\n",
        "        y, x = x[0], x[1:]\n",
        "        y = self.png(y)\n",
        "        for pc in x:\n",
        "            y = torch.cat((y, self.png(pc)), 0)\n",
        "\n",
        "        # y -> B x 20 x 32\n",
        "        if not self.partial:\n",
        "            # LSTM forward\n",
        "            y = y.reshape(B, self.sequence_length, y.size(-1))\n",
        "            h0 = torch.zeros(self.num_layers, y.size(0), self.hidden_size).to(self.device)\n",
        "            c0 = torch.zeros(self.num_layers, y.size(0), self.hidden_size).to(self.device)\n",
        "            out, _ = self.lstm(y, (h0, c0))\n",
        "            out = out.reshape(out.shape[0], -1)\n",
        "            out = self.fc(out)\n",
        "            # print(out.shape)\n",
        "            # out = nn.functional.normalize(out, dim=-1)\n",
        "            return out\n",
        "\n",
        "        else:\n",
        "            y = y.reshape(B, self.sequence_length * y.size(-1))\n",
        "            out = self.fc(y)\n",
        "            # out = nn.Softmax(-1)(out)\n",
        "            # out = nn.functional.normalize(out, dim=-1)\n",
        "            return out\n"
      ],
      "metadata": {
        "id": "-pt5Pbe9joS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "1sBhXeg9RzIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random as random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfiZprmTIDQZ",
        "outputId": "58aa3a16-3b5e-44dd-f7a5-691cb07f6d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    learning_rate=1e-2,\n",
        "    decay=1e-3,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    num_global_features=64\n",
        "    # num_hidden_layers=3\n",
        ")"
      ],
      "metadata": {
        "id": "TEh4a8Doxgvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training_pipeline(hyperparameters):\n",
        "\n",
        "  with wandb.init(project=\"4d-gesture-recognition\", config=hyperparameters):\n",
        "    config = wandb.config\n",
        "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "    print(model)\n",
        "\n",
        "    train(0, model, train_loader, x_val, y_val, criterion, optimizer, config)\n",
        "\n",
        "    model.partial = False\n",
        "    train(1, model, train_loader, x_val, y_val,  criterion, optimizer, config)\n",
        "\n",
        "    test(model, test_loader)\n",
        "\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "_5kyObKmtkBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "\n",
        "  # Make the data\n",
        "  train_loader = make_loader(x_train, y_train, batch_size=config.batch_size)\n",
        "  test_loader = make_loader(x_test, y_test, batch_size=config.batch_size)\n",
        "\n",
        "  # Make the model\n",
        "  model = PPN(3, config.num_global_features, device).to(device)\n",
        "\n",
        "  # Make the loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate, weight_decay=config.decay, nesterov=True, momentum=0.9)\n",
        "\n",
        "\n",
        "  return model, train_loader, test_loader, criterion, optimizer\n"
      ],
      "metadata": {
        "id": "ISvINfCByGRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(data, label, batch_size):\n",
        "  loader = torch.utils.data.DataLoader([[data[i], label[i]-1] for i in range(len(label))], batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
        "\n",
        "  return loader"
      ],
      "metadata": {
        "id": "w9_27npb0DMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files\n",
        "\n",
        "def train(num_prev_epochs, model, loader,  x_val, y_val, criterion, optimizer, config):\n",
        "\n",
        "  wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "  total_batches = len(loader) * config.epochs\n",
        "  example_ct = 0\n",
        "  batch_ct = 0\n",
        "  min_loss, best_model = 10, None\n",
        "  x_val, y_val = x_val.to(device).float(), y_val.to(device)\n",
        "\n",
        "  print(\"start training...\")\n",
        "\n",
        "  for epoch in tqdm(range(config.epochs)):\n",
        "    for _, (data, labels) in enumerate(loader):\n",
        "      loss, accuracy = train_batch(data, labels, model, optimizer, criterion)\n",
        "      example_ct += len(data)\n",
        "      batch_ct += 1\n",
        "\n",
        "      if ((batch_ct + 1) % 25) == 0:\n",
        "        train_log(loss, accuracy, example_ct, num_prev_epochs * config.epochs + epoch)\n",
        "      \n",
        "    # Save the best model which makes the best validation accuracy\n",
        "    val_pred = model(x_val)\n",
        "    val_loss = criterion(val_pred, y_val)\n",
        "    val_accuracy = sum(torch.argmax(val_pred, dim=-1) == y_val) / 100\n",
        "    val_log(val_loss, val_accuracy, num_prev_epochs * config.epochs + epoch)\n",
        "\n",
        "    if val_loss < min_loss:\n",
        "      min_loss = val_loss\n",
        "      torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/674 Project/saved_best_model')\n",
        "      print(\"updated the best model...\")\n",
        "\n",
        "\n",
        "def train_batch(data, labels, model, optimizer, criterion):\n",
        "  data, labels = data.to(device).float(), labels.to(device)\n",
        "\n",
        "  # forward pass\n",
        "  out = model(data)\n",
        "  loss = criterion(out, labels)\n",
        "  accuracy = sum(torch.argmax(out, dim=-1) == labels) / 100\n",
        "\n",
        "  # backward pass\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  # step with optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss, accuracy\n"
      ],
      "metadata": {
        "id": "yrkxaI0X2wvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, accuracy, example_ct, epoch):\n",
        "  wandb.log({\"epoch\": epoch, \"train loss\": loss}, step=epoch)\n",
        "  wandb.log({\"epoch\": epoch, \"train accuracy\": accuracy}, step=epoch)\n",
        "  print(\"epoch: \" +str(epoch).zfill(3)+ \"| \"+str(example_ct).zfill(5) + f\" examples | loss: {loss: .3f}\")"
      ],
      "metadata": {
        "id": "lOWvbGKs3_1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_log(val_loss, val_accuracy, epoch):\n",
        "  wandb.log({\"epoch\": epoch, \"val loss\": val_loss}, step=epoch)\n",
        "  wandb.log({\"epoch\": epoch, \"val accuracy\": val_accuracy}, step=epoch)"
      ],
      "metadata": {
        "id": "Ct7SoTd3nNMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct, total = 0, 0\n",
        "    for data, labels in test_loader:\n",
        "      data, labels = data.to(device).float(), labels.to(device)\n",
        "      print(\"labels: \", labels)\n",
        "      out = model(data)\n",
        "      _, predicted = torch.max(out.data, 1)\n",
        "      print(\"predicted: \", predicted)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print(f\"Accuracy of the model on the {total} \" + f\"test data: {100 * correct / total}%\")\n",
        "    wandb.log({\"test accuracy\": correct / total})\n",
        "\n",
        "  torch.onnx.export(model, data, \"model.onnx\")\n",
        "  wandb.save(\"model.onnx\")"
      ],
      "metadata": {
        "id": "jIYHi98O4SI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_training_pipeline(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fe9ad06dc39a44908a0e7b60e24bce8b",
            "ef97511b2e13412b8a214d34baeb482b",
            "cd03f2dd5d494fa484fda65625872376",
            "6a4984b81ffe4b3e9ac2a9458093ed9e",
            "70b25a35da91452ebd2cb2eeae74a67f",
            "0040bcdd78f748b6b5bbccb2ac952172",
            "7feb9f255e3645bea5ae0b44e65b0ee9",
            "d5a5ef1ceb184834a5641006ea6a9873",
            "5bd8ec77b0a3497f950f905ba13f820e",
            "2fa9ba01c8f04141a66d5c829c41025d",
            "562ab25b81f7498ca81591f2f63b1800",
            "4a35bb583d9c49b78aab97ab1c7a8d51",
            "5c824afc73214f249bc7c0e8a4403058",
            "34f4246e7af8495d8e283c538271ab9d",
            "0240c35318134c4484ba0d9e68259696",
            "535c914c6a084f5f8e498fed7d56705f",
            "65195f34d7da45b2a5d4736879f004f8",
            "c6c6771f2c2c4d77b9ced3547bb0936c",
            "0f7fc6856a934d8f9694c6ddb3502d5d",
            "d2d10343f9ac40c88540c5690bc04f6f",
            "6ef2bd1b1752469e9f59073d18262930",
            "e9818759859846a3900424dca136b3f7",
            "1f7f227662e14175863ca1446c810c72",
            "3ad871c007ab433f9d6ee71c82235dca",
            "efa6bf9c33224a5fb7ea485744e6f44c",
            "d1a7d1e51b0245a6b4600701c370e0d2",
            "7f0122c43f7541de977dc1152a64f892",
            "dfa5da56a2ca42238984684c12c59a31",
            "45411dc92e1d4d67b379a7dbf6ea6668",
            "a8670b9a67a841db99f72c33b53a342a"
          ]
        },
        "id": "r3kw6S_S48hn",
        "outputId": "c38dea85-6210-444f-a562-347df739c733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220730_202329-vozn6jb9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sryu/4d-gesture-recognition/runs/vozn6jb9\" target=\"_blank\">volcanic-shape-44</a></strong> to <a href=\"https://wandb.ai/sryu/4d-gesture-recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPN(\n",
            "  (png): pnGroup(\n",
            "    (point_net): PointNet(\n",
            "      (mlp): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Linear(in_features=3, out_features=32, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): LeakyReLU(negative_slope=0.2)\n",
            "        )\n",
            "      )\n",
            "      (featureExtractionLayer): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Sequential(\n",
            "            (0): Linear(in_features=3, out_features=32, bias=True)\n",
            "            (1): LeakyReLU(negative_slope=0.2)\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "            (1): LeakyReLU(negative_slope=0.2)\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (1): LeakyReLU(negative_slope=0.2)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lstm): LSTM(64, 64, num_layers=3, batch_first=True)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=128, bias=True)\n",
            "    (1): Dropout(p=0.2, inplace=False)\n",
            "    (2): Linear(in_features=128, out_features=14, bias=True)\n",
            "  )\n",
            ")\n",
            "start training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9ad06dc39a44908a0e7b60e24bce8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 000| 00768 examples | loss:  2.655\n",
            "updated the best model...\n",
            "epoch: 001| 01539 examples | loss:  2.651\n",
            "epoch: 002| 02310 examples | loss:  2.660\n",
            "epoch: 003| 03081 examples | loss:  2.640\n",
            "updated the best model...\n",
            "epoch: 004| 03852 examples | loss:  2.631\n",
            "epoch: 005| 04623 examples | loss:  2.624\n",
            "updated the best model...\n",
            "epoch: 006| 05394 examples | loss:  2.635\n",
            "epoch: 007| 06165 examples | loss:  2.649\n",
            "epoch: 008| 06936 examples | loss:  2.638\n",
            "epoch: 009| 07707 examples | loss:  2.626\n",
            "epoch: 010| 08478 examples | loss:  2.643\n",
            "updated the best model...\n",
            "epoch: 011| 09249 examples | loss:  2.638\n",
            "epoch: 011| 10020 examples | loss:  2.646\n",
            "updated the best model...\n",
            "epoch: 012| 10820 examples | loss:  2.628\n",
            "updated the best model...\n",
            "epoch: 013| 11591 examples | loss:  2.644\n",
            "epoch: 014| 12362 examples | loss:  2.634\n",
            "updated the best model...\n",
            "epoch: 015| 13133 examples | loss:  2.631\n",
            "updated the best model...\n",
            "epoch: 016| 13904 examples | loss:  2.639\n",
            "updated the best model...\n",
            "epoch: 017| 14675 examples | loss:  2.633\n",
            "updated the best model...\n",
            "epoch: 018| 15446 examples | loss:  2.640\n",
            "updated the best model...\n",
            "epoch: 019| 16217 examples | loss:  2.619\n",
            "updated the best model...\n",
            "epoch: 020| 16988 examples | loss:  2.635\n",
            "updated the best model...\n",
            "epoch: 021| 17759 examples | loss:  2.624\n",
            "updated the best model...\n",
            "epoch: 022| 18530 examples | loss:  2.626\n",
            "updated the best model...\n",
            "epoch: 023| 19301 examples | loss:  2.609\n",
            "updated the best model...\n",
            "epoch: 024| 20072 examples | loss:  2.635\n",
            "epoch: 024| 20872 examples | loss:  2.629\n",
            "updated the best model...\n",
            "epoch: 025| 21643 examples | loss:  2.624\n",
            "updated the best model...\n",
            "epoch: 026| 22414 examples | loss:  2.593\n",
            "updated the best model...\n",
            "epoch: 027| 23185 examples | loss:  2.551\n",
            "updated the best model...\n",
            "epoch: 028| 23956 examples | loss:  2.614\n",
            "updated the best model...\n",
            "epoch: 029| 24727 examples | loss:  2.555\n",
            "updated the best model...\n",
            "epoch: 030| 25498 examples | loss:  2.564\n",
            "updated the best model...\n",
            "epoch: 031| 26269 examples | loss:  2.535\n",
            "updated the best model...\n",
            "epoch: 032| 27040 examples | loss:  2.561\n",
            "updated the best model...\n",
            "epoch: 033| 27811 examples | loss:  2.448\n",
            "updated the best model...\n",
            "epoch: 034| 28582 examples | loss:  2.250\n",
            "updated the best model...\n",
            "epoch: 035| 29353 examples | loss:  2.287\n",
            "updated the best model...\n",
            "epoch: 036| 30124 examples | loss:  2.225\n",
            "epoch: 036| 30895 examples | loss:  3.729\n",
            "epoch: 037| 31695 examples | loss:  2.161\n",
            "epoch: 038| 32466 examples | loss:  2.043\n",
            "updated the best model...\n",
            "epoch: 039| 33237 examples | loss:  2.386\n",
            "updated the best model...\n",
            "epoch: 040| 34008 examples | loss:  2.301\n",
            "updated the best model...\n",
            "epoch: 041| 34779 examples | loss:  2.438\n",
            "epoch: 042| 35550 examples | loss:  2.517\n",
            "epoch: 043| 36321 examples | loss:  2.120\n",
            "epoch: 044| 37092 examples | loss:  2.032\n",
            "epoch: 045| 37863 examples | loss:  2.226\n",
            "epoch: 046| 38634 examples | loss:  1.885\n",
            "epoch: 047| 39405 examples | loss:  1.983\n",
            "updated the best model...\n",
            "epoch: 048| 40176 examples | loss:  2.400\n",
            "epoch: 049| 40947 examples | loss:  1.950\n",
            "epoch: 049| 41747 examples | loss:  1.827\n",
            "updated the best model...\n",
            "epoch: 050| 42518 examples | loss:  2.516\n",
            "epoch: 051| 43289 examples | loss:  2.150\n",
            "updated the best model...\n",
            "epoch: 052| 44060 examples | loss:  1.912\n",
            "updated the best model...\n",
            "epoch: 053| 44831 examples | loss:  2.393\n",
            "updated the best model...\n",
            "epoch: 054| 45602 examples | loss:  2.410\n",
            "epoch: 055| 46373 examples | loss:  1.846\n",
            "updated the best model...\n",
            "epoch: 056| 47144 examples | loss:  2.527\n",
            "updated the best model...\n",
            "epoch: 057| 47915 examples | loss:  1.757\n",
            "updated the best model...\n",
            "epoch: 058| 48686 examples | loss:  1.732\n",
            "epoch: 059| 49457 examples | loss:  1.613\n",
            "updated the best model...\n",
            "epoch: 060| 50228 examples | loss:  2.104\n",
            "updated the best model...\n",
            "epoch: 061| 50999 examples | loss:  1.761\n",
            "epoch: 061| 51770 examples | loss:  1.966\n",
            "updated the best model...\n",
            "epoch: 062| 52570 examples | loss:  1.953\n",
            "epoch: 063| 53341 examples | loss:  1.568\n",
            "updated the best model...\n",
            "epoch: 064| 54112 examples | loss:  1.921\n",
            "updated the best model...\n",
            "epoch: 065| 54883 examples | loss:  1.433\n",
            "updated the best model...\n",
            "epoch: 066| 55654 examples | loss:  1.956\n",
            "epoch: 067| 56425 examples | loss:  1.786\n",
            "epoch: 068| 57196 examples | loss:  1.419\n",
            "epoch: 069| 57967 examples | loss:  1.927\n",
            "epoch: 070| 58738 examples | loss:  1.709\n",
            "updated the best model...\n",
            "epoch: 071| 59509 examples | loss:  1.438\n",
            "epoch: 072| 60280 examples | loss:  1.665\n",
            "updated the best model...\n",
            "epoch: 073| 61051 examples | loss:  1.610\n",
            "epoch: 074| 61822 examples | loss:  1.487\n",
            "epoch: 074| 62622 examples | loss:  1.391\n",
            "updated the best model...\n",
            "epoch: 075| 63393 examples | loss:  1.233\n",
            "epoch: 076| 64164 examples | loss:  1.768\n",
            "epoch: 077| 64935 examples | loss:  1.331\n",
            "epoch: 078| 65706 examples | loss:  1.557\n",
            "epoch: 079| 66477 examples | loss:  1.770\n",
            "updated the best model...\n",
            "epoch: 080| 67248 examples | loss:  1.050\n",
            "epoch: 081| 68019 examples | loss:  1.537\n",
            "updated the best model...\n",
            "epoch: 082| 68790 examples | loss:  2.288\n",
            "updated the best model...\n",
            "epoch: 083| 69561 examples | loss:  1.251\n",
            "epoch: 084| 70332 examples | loss:  1.510\n",
            "updated the best model...\n",
            "epoch: 085| 71103 examples | loss:  1.289\n",
            "epoch: 086| 71874 examples | loss:  1.837\n",
            "epoch: 086| 72645 examples | loss:  0.483\n",
            "updated the best model...\n",
            "epoch: 087| 73445 examples | loss:  0.995\n",
            "epoch: 088| 74216 examples | loss:  0.985\n",
            "updated the best model...\n",
            "epoch: 089| 74987 examples | loss:  1.294\n",
            "epoch: 090| 75758 examples | loss:  1.266\n",
            "epoch: 091| 76529 examples | loss:  1.273\n",
            "epoch: 092| 77300 examples | loss:  1.036\n",
            "epoch: 093| 78071 examples | loss:  1.041\n",
            "epoch: 094| 78842 examples | loss:  1.100\n",
            "epoch: 095| 79613 examples | loss:  0.890\n",
            "updated the best model...\n",
            "epoch: 096| 80384 examples | loss:  0.440\n",
            "epoch: 097| 81155 examples | loss:  0.639\n",
            "epoch: 098| 81926 examples | loss:  0.605\n",
            "epoch: 099| 82697 examples | loss:  0.663\n",
            "epoch: 099| 83497 examples | loss:  1.044\n",
            "updated the best model...\n",
            "start training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a35bb583d9c49b78aab97ab1c7a8d51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 100| 00768 examples | loss:  2.628\n",
            "updated the best model...\n",
            "epoch: 101| 01539 examples | loss:  2.407\n",
            "updated the best model...\n",
            "epoch: 102| 02310 examples | loss:  2.285\n",
            "updated the best model...\n",
            "epoch: 103| 03081 examples | loss:  2.091\n",
            "updated the best model...\n",
            "epoch: 104| 03852 examples | loss:  2.000\n",
            "updated the best model...\n",
            "epoch: 105| 04623 examples | loss:  1.918\n",
            "updated the best model...\n",
            "epoch: 106| 05394 examples | loss:  2.056\n",
            "updated the best model...\n",
            "epoch: 107| 06165 examples | loss:  1.674\n",
            "updated the best model...\n",
            "epoch: 108| 06936 examples | loss:  1.683\n",
            "updated the best model...\n",
            "epoch: 109| 07707 examples | loss:  1.358\n",
            "updated the best model...\n",
            "epoch: 110| 08478 examples | loss:  1.682\n",
            "epoch: 111| 09249 examples | loss:  1.462\n",
            "epoch: 111| 10020 examples | loss:  0.817\n",
            "epoch: 112| 10820 examples | loss:  1.570\n",
            "updated the best model...\n",
            "epoch: 113| 11591 examples | loss:  1.644\n",
            "epoch: 114| 12362 examples | loss:  1.749\n",
            "epoch: 115| 13133 examples | loss:  1.114\n",
            "updated the best model...\n",
            "epoch: 116| 13904 examples | loss:  0.924\n",
            "epoch: 117| 14675 examples | loss:  1.324\n",
            "epoch: 118| 15446 examples | loss:  1.287\n",
            "epoch: 119| 16217 examples | loss:  0.727\n",
            "updated the best model...\n",
            "epoch: 120| 16988 examples | loss:  0.708\n",
            "epoch: 121| 17759 examples | loss:  0.848\n",
            "epoch: 122| 18530 examples | loss:  1.277\n",
            "epoch: 123| 19301 examples | loss:  0.814\n",
            "epoch: 124| 20072 examples | loss:  0.768\n",
            "epoch: 124| 20872 examples | loss:  0.840\n",
            "epoch: 125| 21643 examples | loss:  0.801\n",
            "epoch: 126| 22414 examples | loss:  0.654\n",
            "epoch: 127| 23185 examples | loss:  0.680\n",
            "updated the best model...\n",
            "epoch: 128| 23956 examples | loss:  0.667\n",
            "updated the best model...\n",
            "epoch: 129| 24727 examples | loss:  0.536\n",
            "updated the best model...\n",
            "epoch: 130| 25498 examples | loss:  0.494\n",
            "epoch: 131| 26269 examples | loss:  0.307\n",
            "epoch: 132| 27040 examples | loss:  0.358\n",
            "epoch: 133| 27811 examples | loss:  0.444\n",
            "epoch: 134| 28582 examples | loss:  0.302\n",
            "epoch: 135| 29353 examples | loss:  0.451\n",
            "epoch: 136| 30124 examples | loss:  0.440\n",
            "epoch: 136| 30895 examples | loss:  0.287\n",
            "epoch: 137| 31695 examples | loss:  0.290\n",
            "epoch: 138| 32466 examples | loss:  0.544\n",
            "updated the best model...\n",
            "epoch: 139| 33237 examples | loss:  0.209\n",
            "epoch: 140| 34008 examples | loss:  0.397\n",
            "epoch: 141| 34779 examples | loss:  0.183\n",
            "epoch: 142| 35550 examples | loss:  0.579\n",
            "epoch: 143| 36321 examples | loss:  0.284\n",
            "epoch: 144| 37092 examples | loss:  0.126\n",
            "epoch: 145| 37863 examples | loss:  0.169\n",
            "epoch: 146| 38634 examples | loss:  0.780\n",
            "epoch: 147| 39405 examples | loss:  0.212\n",
            "epoch: 148| 40176 examples | loss:  0.163\n",
            "epoch: 149| 40947 examples | loss:  0.082\n",
            "epoch: 149| 41747 examples | loss:  0.080\n",
            "epoch: 150| 42518 examples | loss:  0.139\n",
            "epoch: 151| 43289 examples | loss:  0.169\n",
            "epoch: 152| 44060 examples | loss:  0.312\n",
            "epoch: 153| 44831 examples | loss:  0.353\n",
            "epoch: 154| 45602 examples | loss:  0.367\n",
            "epoch: 155| 46373 examples | loss:  0.247\n",
            "epoch: 156| 47144 examples | loss:  0.731\n",
            "epoch: 157| 47915 examples | loss:  0.480\n",
            "epoch: 158| 48686 examples | loss:  0.462\n",
            "epoch: 159| 49457 examples | loss:  3.051\n",
            "epoch: 160| 50228 examples | loss:  2.659\n",
            "epoch: 161| 50999 examples | loss:  1.419\n",
            "epoch: 161| 51770 examples | loss:  1.841\n",
            "epoch: 162| 52570 examples | loss:  1.474\n",
            "epoch: 163| 53341 examples | loss:  1.355\n",
            "epoch: 164| 54112 examples | loss:  1.310\n",
            "epoch: 165| 54883 examples | loss:  0.937\n",
            "epoch: 166| 55654 examples | loss:  1.419\n",
            "epoch: 167| 56425 examples | loss:  0.714\n",
            "epoch: 168| 57196 examples | loss:  0.801\n",
            "epoch: 169| 57967 examples | loss:  0.475\n",
            "epoch: 170| 58738 examples | loss:  0.381\n",
            "epoch: 171| 59509 examples | loss:  0.819\n",
            "updated the best model...\n",
            "epoch: 172| 60280 examples | loss:  0.576\n",
            "epoch: 173| 61051 examples | loss:  0.540\n",
            "epoch: 174| 61822 examples | loss:  1.252\n",
            "epoch: 174| 62622 examples | loss:  0.606\n",
            "epoch: 175| 63393 examples | loss:  0.149\n",
            "epoch: 176| 64164 examples | loss:  0.174\n",
            "updated the best model...\n",
            "epoch: 177| 64935 examples | loss:  0.322\n",
            "updated the best model...\n",
            "epoch: 178| 65706 examples | loss:  0.094\n",
            "epoch: 179| 66477 examples | loss:  0.108\n",
            "epoch: 180| 67248 examples | loss:  0.206\n",
            "epoch: 181| 68019 examples | loss:  0.149\n",
            "epoch: 182| 68790 examples | loss:  0.134\n",
            "epoch: 183| 69561 examples | loss:  0.262\n",
            "epoch: 184| 70332 examples | loss:  0.295\n",
            "epoch: 185| 71103 examples | loss:  0.107\n",
            "epoch: 186| 71874 examples | loss:  0.085\n",
            "epoch: 186| 72645 examples | loss:  0.007\n",
            "epoch: 187| 73445 examples | loss:  0.163\n",
            "epoch: 188| 74216 examples | loss:  0.061\n",
            "epoch: 189| 74987 examples | loss:  0.046\n",
            "epoch: 190| 75758 examples | loss:  0.417\n",
            "epoch: 191| 76529 examples | loss:  0.260\n",
            "epoch: 192| 77300 examples | loss:  0.239\n",
            "epoch: 193| 78071 examples | loss:  0.031\n",
            "epoch: 194| 78842 examples | loss:  0.060\n",
            "epoch: 195| 79613 examples | loss:  0.052\n",
            "epoch: 196| 80384 examples | loss:  0.039\n",
            "epoch: 197| 81155 examples | loss:  0.027\n",
            "epoch: 198| 81926 examples | loss:  0.024\n",
            "updated the best model...\n",
            "epoch: 199| 82697 examples | loss:  0.006\n",
            "epoch: 199| 83497 examples | loss:  0.055\n",
            "labels:  tensor([13,  6,  7, 13,  0,  7,  6,  0,  3,  2,  2,  3,  0, 12,  7,  3,  8, 11,\n",
            "         7,  6, 11, 11,  3, 11,  7, 10,  3,  2,  6,  2,  8,  5],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([13,  6,  5, 13,  3,  7,  6,  0,  3,  2,  8,  0,  1, 12, 10,  3,  8, 11,\n",
            "         7,  6, 11, 11,  3, 11,  7, 10,  3,  2,  6,  3,  8,  5],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([13,  7, 13,  6, 12, 13,  5,  9,  5,  7, 10, 10,  3,  7,  4,  1,  4,  7,\n",
            "         9,  8,  2,  2, 11,  5,  3,  2,  2, 12, 13,  5, 10,  0],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([13,  7,  3,  6, 12,  7,  5,  9,  9,  7, 10, 10,  3,  7,  4,  3,  4,  7,\n",
            "         9, 13,  2,  2, 11,  5,  3,  2,  2, 12, 13,  5, 10,  0],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 8, 10, 13,  1,  0, 11,  1,  5,  7, 12,  9,  6,  8, 10, 11,  8,  6,  2,\n",
            "        12,  2,  2,  4, 10,  0, 12,  1,  9,  2, 12,  9,  0, 13],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([13,  8, 13,  1,  0, 11,  1,  5,  7,  6,  9,  9,  2, 10, 11,  8, 13,  2,\n",
            "         6,  2,  2,  4, 10,  0, 12,  1,  9,  2, 12,  9,  0, 13],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 2,  9,  9,  0,  8,  4,  1,  4,  6, 11,  7, 11,  7,  5,  3,  7,  2,  4,\n",
            "         9,  0,  0,  3,  3,  4,  4,  1,  3,  5,  5,  4, 12,  0],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 8,  8,  9,  0,  8,  4,  1,  6,  6, 11,  7, 11,  5,  5,  3,  7,  2,  3,\n",
            "         9,  0,  0,  3,  3,  4,  0,  8,  3,  5,  5,  9,  6,  0],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 0,  9,  4,  7,  9,  9, 13,  6,  8,  9,  1, 10, 11, 12, 13,  5, 13,  5,\n",
            "         9,  2,  0,  1,  0, 12,  3,  4,  5, 13,  7, 11,  9,  1],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 3,  9,  4,  7,  9,  9,  3,  6,  8,  9,  1, 10, 11, 13, 13,  5, 13,  5,\n",
            "        10,  2,  0,  1,  0, 12,  3,  4,  5,  6,  5, 11,  9,  0],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 3,  6, 12,  3,  8,  5,  7, 11,  4,  6,  2, 10,  2, 10,  0, 12,  2,  5,\n",
            "        10,  7, 11,  1,  7,  8, 12,  8,  1,  5, 10,  5, 12,  3],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 3,  6,  6,  3,  8,  5,  7, 11,  4,  6,  2, 10, 13, 10,  0, 12,  8,  5,\n",
            "         8,  7,  0,  1,  7, 13, 12,  8,  1,  5, 10,  5, 12,  3],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 4,  1,  2,  4,  5,  0, 10,  6,  3, 12, 13,  4,  7, 12, 11, 10,  0,  3,\n",
            "         9, 12, 11, 10, 12,  4,  8,  0,  8, 12,  6,  3,  8, 11],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 4,  5,  3,  4,  5,  3, 10,  6,  3, 12,  6,  4,  4, 12, 11, 11,  0,  3,\n",
            "         9, 12, 11, 10,  6,  4,  8,  0,  1, 12,  6,  3,  8, 11],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([10,  6,  3, 10, 13,  0,  6, 12, 13,  1, 11, 13, 11, 11,  7, 10,  4,  6,\n",
            "         2, 13,  9,  6,  4,  3,  0,  9,  6, 10,  1, 10,  1,  8],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([10,  6,  3, 10, 13,  3,  6, 12, 13,  1, 11, 13,  7, 11,  7, 10,  3, 13,\n",
            "         2, 13,  9,  6,  4,  3,  0,  9,  6, 10,  1, 10,  1,  8],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 8,  9,  5,  8, 13, 13,  1, 11,  9,  1,  1,  1,  8,  5,  9, 13,  6,  4,\n",
            "         1,  8,  6,  4,  5], device='cuda:0')\n",
            "predicted:  tensor([ 8,  9,  5,  8, 13,  3,  1, 11,  9,  1,  1,  1,  8,  5,  4, 13,  6,  4,\n",
            "         1, 13,  6,  4,  5], device='cuda:0')\n",
            "Accuracy of the model on the 279 test data: 79.92831541218638%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:285: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return tensor.shape == torch.Size([0]) or (~torch.isfinite(tensor)).all().item()\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:288: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if not torch.isfinite(tensor).all():\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:203: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  tmin = flat.min().item()\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:204: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  tmax = flat.max().item()\n",
            "/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py:239: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:3227: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  + \"or define the initial states (h0/c0) as inputs of the model. \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.534 MB of 1.534 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7f227662e14175863ca1446c810c72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>train accuracy</td><td>▁▂▁▂▂▁▂▃▂▃▃▃▁▅▅▅▄▆▅▇▃▄▁▅▆▇▇▇▇▇█▇▅▆▇▇████</td></tr><tr><td>train loss</td><td>███████▇▇▇▇▆▆▆▅▄▅▄▄▃▇▅▃▄▃▃▂▂▂▁▂▂▅▃▂▂▂▁▁▁</td></tr><tr><td>val accuracy</td><td>▁▁▁▁▁▂▂▂▃▃▃▄▅▄▄▄▅▅▅▆▂▅▅▆▄▇▇▇██▅▇▅▇▆█████</td></tr><tr><td>val loss</td><td>██████▇▆▆▆▆▅▅▅▅▅▄▄▅▃▇▄▄▃▆▂▂▂▁▂▇▂▃▂▆▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>test accuracy</td><td>0.79928</td></tr><tr><td>train accuracy</td><td>0.31</td></tr><tr><td>train loss</td><td>0.05524</td></tr><tr><td>val accuracy</td><td>2.17</td></tr><tr><td>val loss</td><td>0.99745</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">volcanic-shape-44</strong>: <a href=\"https://wandb.ai/sryu/4d-gesture-recognition/runs/vozn6jb9\" target=\"_blank\">https://wandb.ai/sryu/4d-gesture-recognition/runs/vozn6jb9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220730_202329-vozn6jb9/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cpu')\n",
        "test_loader = make_loader(x_test, y_test, batch_size=32)\n",
        "# saved_model = open('/content/drive/My Drive/Colab Notebooks/674 Project/saved_model', 'rb')\n",
        "best_model = PPN(3, 64, device).to(device)\n",
        "# print(model)\n",
        "best_model.partial = False\n",
        "best_model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/674 Project/saved_best_model'))\n",
        "test(best_model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7voksR37fh6j",
        "outputId": "b8b46f3c-57f1-4270-8907-a7f294f8fe17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  tensor([ 7,  3,  9, 13,  0, 13,  8, 12,  0,  2,  1,  0,  6,  1,  6,  2,  5,  8,\n",
            "         3, 12,  3, 13, 13,  9,  7,  4,  4, 13, 11, 12,  7,  6],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 7,  3,  9, 13,  0,  3, 13, 12,  0,  2,  1,  0,  6,  1,  6,  2,  5,  8,\n",
            "         3, 12,  3,  7,  6,  9,  7,  4,  4,  6, 11, 12,  7,  6],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 1,  8,  0, 11,  5,  4,  1,  0, 12, 12,  7, 12,  5, 10,  1,  3,  9, 13,\n",
            "         8,  3,  7,  5,  9,  3,  5,  4,  8, 10,  1,  0, 13,  9],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 4, 13,  0, 11,  9,  4,  1,  0,  6, 12,  7, 12,  5, 10,  1,  3,  9, 13,\n",
            "         8,  3,  7,  5,  9,  3,  5,  4,  8,  8,  0,  0, 13,  9],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([10,  9, 11,  3, 12,  5,  4,  6,  2,  9,  6, 12, 11,  2,  1,  6,  7, 10,\n",
            "         9,  3,  0,  3,  6, 13,  2, 11, 12,  4,  6, 13,  7,  2],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([10,  9, 11,  3, 12,  5,  4,  6,  2,  9,  6, 12, 11,  2,  1,  6,  7, 10,\n",
            "         8,  0,  0,  3,  6, 13,  2, 11,  6,  4,  9, 13,  4,  2],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 4,  6,  2,  9,  4,  1, 10, 11,  1, 10,  7, 11, 10,  0,  9,  7,  8,  7,\n",
            "         1,  1, 13, 11,  8,  2, 12,  5,  1,  3,  7,  1,  3,  8],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([13,  6, 13,  9,  4,  2, 10, 11,  1, 10,  5, 11, 10,  0,  9,  7,  8,  7,\n",
            "         1,  1, 13, 11,  8,  2, 12,  5,  1,  3,  7,  1,  3, 13],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 0,  7, 10,  5, 12, 10,  7, 10, 10,  1, 11,  0,  6,  7,  0, 11, 11,  6,\n",
            "         2,  5,  8, 11,  8, 12,  6,  5,  7,  3,  4,  0,  5,  4],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 0,  9,  8,  5, 12, 10,  7, 10, 10,  1, 11,  0, 13,  7,  0, 11, 11,  6,\n",
            "         2,  5,  8, 11,  8, 12,  6,  5,  7,  3,  4,  3,  5,  4],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 9,  1, 10,  8,  2,  9,  5,  5,  8, 10,  2,  2,  6, 13, 10,  0,  5,  3,\n",
            "         2,  7,  4,  5,  8,  6,  9,  5,  1,  0,  6,  6, 12,  0],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 9,  1, 10,  8,  2,  9,  5,  5,  8, 10,  8,  8,  6, 13, 10,  0,  5,  3,\n",
            "         7,  7,  4,  5,  8,  6,  9,  5,  1,  0,  6,  6, 13,  0],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 0,  5, 11,  0,  5,  9, 12,  2,  5,  2,  1, 13, 11,  4,  3,  3,  7, 13,\n",
            "         4, 10,  3,  4, 11,  7, 13,  2, 11,  3,  9, 13, 13, 13],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([ 3,  5,  0,  0,  5,  9, 12,  2,  5,  2,  1,  3, 11,  0,  3,  3,  7, 13,\n",
            "         4, 10,  3,  4, 12,  7, 13,  2, 11,  3,  9, 13, 13, 13],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([12,  3,  0, 11,  9,  9,  4,  3,  2,  9,  8,  7,  8,  0, 12,  8,  4,  3,\n",
            "         5,  1,  4, 12, 13, 10, 10, 11, 12,  8,  4,  2,  4,  6],\n",
            "       device='cuda:0')\n",
            "predicted:  tensor([12,  3,  0, 11,  9,  9,  4,  3,  2,  9,  8,  7,  8,  0,  6,  8,  4,  3,\n",
            "         5,  1,  4, 12, 13, 10, 11,  7, 12,  8,  4,  2,  4,  6],\n",
            "       device='cuda:0')\n",
            "labels:  tensor([ 6,  6,  2, 10,  4,  8, 10, 10,  8,  2,  6,  1, 12, 13,  1,  9,  0, 13,\n",
            "        11,  7, 12,  9, 11], device='cuda:0')\n",
            "predicted:  tensor([ 6,  6,  2, 10,  4, 13, 10, 10,  1,  3,  6,  1, 12, 13,  1,  9,  0, 13,\n",
            "        11,  7, 12,  4, 11], device='cuda:0')\n",
            "Accuracy of the model on the 279 test data: 85.30465949820788%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fa5822b140bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/674 Project/saved_best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-e55cc539fb4d>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy of the model on the {total} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"test data: {100 * correct / total}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"test accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe9ad06dc39a44908a0e7b60e24bce8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef97511b2e13412b8a214d34baeb482b",
              "IPY_MODEL_cd03f2dd5d494fa484fda65625872376",
              "IPY_MODEL_6a4984b81ffe4b3e9ac2a9458093ed9e"
            ],
            "layout": "IPY_MODEL_70b25a35da91452ebd2cb2eeae74a67f"
          }
        },
        "ef97511b2e13412b8a214d34baeb482b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0040bcdd78f748b6b5bbccb2ac952172",
            "placeholder": "​",
            "style": "IPY_MODEL_7feb9f255e3645bea5ae0b44e65b0ee9",
            "value": "100%"
          }
        },
        "cd03f2dd5d494fa484fda65625872376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a5ef1ceb184834a5641006ea6a9873",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bd8ec77b0a3497f950f905ba13f820e",
            "value": 100
          }
        },
        "6a4984b81ffe4b3e9ac2a9458093ed9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa9ba01c8f04141a66d5c829c41025d",
            "placeholder": "​",
            "style": "IPY_MODEL_562ab25b81f7498ca81591f2f63b1800",
            "value": " 100/100 [22:29&lt;00:00, 13.66s/it]"
          }
        },
        "70b25a35da91452ebd2cb2eeae74a67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0040bcdd78f748b6b5bbccb2ac952172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7feb9f255e3645bea5ae0b44e65b0ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5a5ef1ceb184834a5641006ea6a9873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd8ec77b0a3497f950f905ba13f820e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fa9ba01c8f04141a66d5c829c41025d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562ab25b81f7498ca81591f2f63b1800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a35bb583d9c49b78aab97ab1c7a8d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c824afc73214f249bc7c0e8a4403058",
              "IPY_MODEL_34f4246e7af8495d8e283c538271ab9d",
              "IPY_MODEL_0240c35318134c4484ba0d9e68259696"
            ],
            "layout": "IPY_MODEL_535c914c6a084f5f8e498fed7d56705f"
          }
        },
        "5c824afc73214f249bc7c0e8a4403058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65195f34d7da45b2a5d4736879f004f8",
            "placeholder": "​",
            "style": "IPY_MODEL_c6c6771f2c2c4d77b9ced3547bb0936c",
            "value": "100%"
          }
        },
        "34f4246e7af8495d8e283c538271ab9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7fc6856a934d8f9694c6ddb3502d5d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2d10343f9ac40c88540c5690bc04f6f",
            "value": 100
          }
        },
        "0240c35318134c4484ba0d9e68259696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef2bd1b1752469e9f59073d18262930",
            "placeholder": "​",
            "style": "IPY_MODEL_e9818759859846a3900424dca136b3f7",
            "value": " 100/100 [22:30&lt;00:00, 14.27s/it]"
          }
        },
        "535c914c6a084f5f8e498fed7d56705f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65195f34d7da45b2a5d4736879f004f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c6771f2c2c4d77b9ced3547bb0936c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f7fc6856a934d8f9694c6ddb3502d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d10343f9ac40c88540c5690bc04f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ef2bd1b1752469e9f59073d18262930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9818759859846a3900424dca136b3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7f227662e14175863ca1446c810c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ad871c007ab433f9d6ee71c82235dca",
              "IPY_MODEL_efa6bf9c33224a5fb7ea485744e6f44c"
            ],
            "layout": "IPY_MODEL_d1a7d1e51b0245a6b4600701c370e0d2"
          }
        },
        "3ad871c007ab433f9d6ee71c82235dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0122c43f7541de977dc1152a64f892",
            "placeholder": "​",
            "style": "IPY_MODEL_dfa5da56a2ca42238984684c12c59a31",
            "value": "1.716 MB of 1.716 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "efa6bf9c33224a5fb7ea485744e6f44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45411dc92e1d4d67b379a7dbf6ea6668",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8670b9a67a841db99f72c33b53a342a",
            "value": 1
          }
        },
        "d1a7d1e51b0245a6b4600701c370e0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0122c43f7541de977dc1152a64f892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa5da56a2ca42238984684c12c59a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45411dc92e1d4d67b379a7dbf6ea6668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8670b9a67a841db99f72c33b53a342a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}